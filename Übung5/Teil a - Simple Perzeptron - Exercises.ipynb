{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil a - Simple Perzeptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zum aufwärmen -> Optional !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Klassifizierung anhand eines Perzeptrons kann formal als binäre oder dichotome Klassifizierung betrachtet werden. Die Ziel-Klassen werden als 1 (positive Klasse) und 0 (negative Klasse) bezeichnet. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau des Perceptrons\n",
    "\n",
    "<img src=\"./Figures/perceptron.png\" alt=\"drawing\" style=\"width:800px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Input $\\vec{x}$\n",
    "\n",
    "\n",
    "$\\vec{x}$ wird als Inputvektor bezeichnet und repräsentiert die Eingangsdaten. Die Werte werden übereinander geschrieben: Spaltenschreibweise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Gewicht $\\vec{w}$ \n",
    "\n",
    "$\\vec{w}$ wird als Gewichtungsvektor bezeichnet. Gewichte stellen die Verbindungen zwischen zwei Neuronen her. Bspw. sendet Neuron A ein Signal an Neuron B. Das Gewicht steuert hierbei, wie stark das Signal in Neuron B ankommt. Ein Wert 0..1 verringert das Signal, ein Wert >1 verstärkt das Signal. Das Gewicht regelt hierbei die Signalstärke. \n",
    "\n",
    "Lernen in neuronalen Netzen bedeutet die Anpassung der Gewichte.\n",
    "\n",
    "Zusätzlich zur Spaltenschreibweise, wird der Gewichtsvektor in Zeilenschreibweise dargestellt, d.h. die Werte werden nebeneinander geschrieben. Hierzu wird dem Gewichtsvektor ein hochgestelltes <i>T</i> angehängt, dies bedeutet <i>transponiert</i>. \n",
    "\n",
    "Der Grund hierfür ist, dass damit die Multiplikation zwischen den Inputwerten und den Gewichten einfacher beschrieben werden kann: <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Gewichtete Summe $s$\n",
    "\n",
    "Die gewichtete Summe bildet die Linearkombination bestehend aus dem Inputvektor $\\vec{x}$ und dem Gewichtungsvektor $\\vec{w}$: <br>\n",
    "s = ${w}_1 \\cdot {x}_1  + {w}_2 \\cdot {x}_2 + ... {w}_n \\cdot {x}_n $.\n",
    "\n",
    "\n",
    "Die Summe aller $w_i \\cdot x_i$ lässt sich kompakt darstellen als: $s = \\sum^{n}_{i=1}w_i \\cdot x_i$. \n",
    " \n",
    "\n",
    "Die Summe der Produkte der Werte von $\\vec{x}$ und $\\vec{w}$ wird als Skalarprodukt zweier Vektoren abgekürzt. Hierbei werden Spaltenvektoren in Zeilenvektoren transformiert: $s= w^T x$.\n",
    "\n",
    "Rechenbeispiel:\n",
    "\n",
    "$\n",
    "\\begin{pmatrix} 1 & 2 & 3 \\end{pmatrix}  \n",
    "\\cdot\n",
    "\\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\\\ \n",
    "\\end{pmatrix}  \n",
    "= 1 \\cdot 4 + 2\\cdot 5 + 3 \\cdot 6 = 32\n",
    "$\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ermittlung des Skalarprodukts\n",
    "\n",
    "Die Multiplikation zweier Vektoren kann anhand der Numpy-Funktion <b>dot()</b> umgesetzt werden. Die Multiplikation wird als <i>Skalarprodukt</i>, <i>Dot-Product</i> oder <i>inneres Produkt</i> bezeichnet. Skalarprodukt, weil das Ergebnis der Multiplikation ein Skalar (dh. ein Wert) ist, und kein Vektor. Dem gegenüber führt der Multiplikationsoperator in Python <b>*</b> die Operation Element für Element aus.\n",
    "\n",
    "Bilden Sie anhand der Vektoren $\\vec{v}_1= [1,2,3]$ und $\\vec{v}_2 = [4,5,6]$, abgebildet als Numpy-Arrays, das Skalarprodukt und die elementweise Multiplikation und zeigen Sie die Unterschiede auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skalarprodukt 32\n",
      "Elementweise Multiplikation [ 4 10 18]\n"
     ]
    }
   ],
   "source": [
    "v1 = np.array([1,2,3])\n",
    "v2 = np.array([4,5,6])\n",
    "\n",
    "print(\"Skalarprodukt\", np.dot(v1,v2))\n",
    "print(\"Elementweise Multiplikation\", v1*v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Stufenfunktion $step$(s)\n",
    "\n",
    "Für die Stufenfunktion wird folgende Funktion definiert: <br>\n",
    "$\n",
    "    step(s) = f(x) = \\left\\{\\begin{array}{lr}\n",
    "        0, & \\text{falls } s < \\theta \\\\\n",
    "        1, & \\text{falls } s \\geq \\theta\n",
    "        \\end{array}\\right\\} \n",
    "$\n",
    "\n",
    "Unabhängig vom Eingabewert der Stufenfunktion ist das Ergebnis stets entweder 0 oder 1. Jedoch ist sie vom Schwellenwert Theta $\\theta$ abhängig, wann der Sprung von 0 auf 1 stattfindet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Output $f_{akt}(\\vec{x})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausgangslage folgender Überlegung ist die gewichtete Summe mit der Stufenfunktion (Heaviside-Funktion): <br>\n",
    "${w}_1 \\cdot {x}_1  + {w}_2 \\cdot {x}_2 + ... {w}_n \\cdot {x}_n \\geq \\theta$.\n",
    "\n",
    "Durch Umformung der Ungleichung wird $\\theta$ auf die linke Seite gebracht. Das Ergebnis ist ein erweiterter Gewichtsvektor, der um eine Dimension für den Schwellenwert erweitert wird. Die neue Dimension wird am Index 0 eingefügt, sodass der ursprüngliche Vektor inklusive Indizes erhalten bleibt: <br>\n",
    "${w}_1 \\cdot {x}_1  + {w}_2 \\cdot {x}_2 + ... {w}_n \\cdot {x}_n -\\theta \\geq  0$.\n",
    "\n",
    "Damit der Schwellenwert an der Stelle 0 eingefügt werden kann, wird $-\\theta$ in $w_0$ umbenannt. Der Vektor $\\vec{x}$ wird ebenfalls um einen Wert erweitert. Der Wert für den Input $x_0$ wird mit dem Wert 1 besetzt. Somit existiert eine einheitliche Form um bei der Notation $\\vec{w}^T \\cdot \\vec{x}$ zu bleiben. Es gilt: <br>\n",
    "${w}_1 \\cdot {x}_1  + {w}_2 \\cdot {x}_2 + ... {w}_n \\cdot {x}_n +w_0 \\cdot x_0 \\geq  0$.\n",
    "\n",
    "Diese Form der Nullgewichtung wird in der Literatur als <i>Bias-Neuron</i> bezeichnet. Dadurch ergibt sich folgendes Schaubild:\n",
    "\n",
    "![title](./Figures/perceptron_erweitert.png)\n",
    "\n",
    "Die Implementierung auf Code-Ebene weicht davon jedoch etwas ab. <br>\n",
    "Anstatt den Eingangsvektor $\\vec{x}$ mit dem Wert 1 zu erweitern, wird der Wert $w_0$ auf die gewichtete Summe addiert. Formal wiefolgt beschrieben (siehe Skript Prof. Link): \n",
    "\n",
    "$s = \\vec{w}^T \\cdot \\vec{x} + w_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Implementierung\n",
    "\n",
    "Im folgenden werden die bisher gewonnenen Erkenntnisse in Code umgesetzt. Die Datengrundlage liefert folgende Tabelle (OR-Problem).\n",
    "\n",
    "<img src=\"./Figures/or-problem.png\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "\n",
    "Ingesamt handelt es sich hierbei um vier Inputvektoren. \n",
    "\n",
    "Für die Fehlerberechnung der Einzelfehler wird für jeden Input-Vektor der berechnete Output mit dem gewünschten Output verglichen. Das Perceptron kann aufgrund der Heaviside-Funktion entsprechend nur 0 oder 1 ausgeben. Der gewünschte Output ist per Definition ebenfalls 0 oder 1. Somit kann die Differenz nur -1, 0, 1 betragen. In diesem Fall gilt es die Betragsfunktion für den Einzelfehler zu berechnen. Denn sonst würde ein Fehler von -1 den Gesamtfehler verringern. <br>\n",
    "\n",
    "Die Einzelfehler der Input-Vektren werden summiert und somit der Gesamtfehler bestimmt. Der Gesamtfehler stellt die Ermittlungsgenauigkeit des Perzeptrons dar. <br>\n",
    "\n",
    "Die Gewichtungen sind mit Werten zu belegen. Experimentieren sie mit den Gewichtungen, sehen sie sich die Fehler an und versuchen sie diese anhand der besprochenen Berechnungen nachzuvollziehen. Wählen Sie die Gewichte so, sodass das OR-Problem gelöst werden kann. \n",
    "\n",
    "## Implementierung\n",
    "\n",
    "Die Implementierung erfolgt innerhalb der Klasse <b>SimplePerceptron</b>. Im folgenden werden die einzelnen Methoden und deren Funktionsweise kurz vorgestellt. <br>\n",
    "\n",
    "### Konstruktor\n",
    "Hier ist nichts zu implementieren. <br>\n",
    "\n",
    "### gewichtete_summe()-Methode:\n",
    "In dieser Methode soll die beschriebene gewichtete Summe $\\vec{w}^T \\cdot \\vec{x} + w_0$ berechnet werden.\n",
    "\n",
    "### heaviside()-Methode:\n",
    "Heaviside-Funktion als Stufenfunktion, dh Schwellenwert ist 0.\n",
    "\n",
    "### perceptron_eval()-Methode:\n",
    "\n",
    "<b>Gewichtungen</b>: <br>\n",
    "Die Gewichtungen in <b>self.w</b> werden mit einem Vektor $\\mathbb R^{m+1}$ initialisiert, m gibt die Anzahl der Dimensionen (Merkmale) in der Datensammlung an. Dem ersten Element dieses Vektors (dies entspricht der Bias-Einheit) wird ein Wert zugeordnet. Gehen Sie von zwei Merkmalen aus (wie oben beschrieben).<br>\n",
    "\n",
    "Implementieren Sie den besprochenen Perceptron-Algorithmus mit den folgenden Schritten:\n",
    "* Berechnung gewichtete Summe\n",
    "* Anwendung der Heaviside-Funktion\n",
    "* Ermittlung des Fehlers\n",
    "* Ermittlung des Gesamtfehlers\n",
    "\n",
    "Geben Sie die den Gesamtfehler als Rückgabewert der Methode zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ueberlegungen zu den Gewichtungen:\n",
    "\n",
    "# w1 * 0 + w2 * 0 + w0 = 0  -->  w0 < 0\n",
    "# w1 * 0 + w2 * 1 + w0 = 1  -->  w2 + w0 >= 0\n",
    "# w1 * 1 + w2 * 0 + w0 = 1  -->  w1 + w0 >= 0\n",
    "# w1 * 1 + w2 * 1 + w0 = 1  -->  w1 + w2 + w0 >= 0\n",
    "\n",
    "# Gewaehlte Gewichte: -1.0, 1.1, 1.1\n",
    "# 1.1 * 0 + 1.1 * 0 - 1.0 = -1.0  -->  w0 < 0\n",
    "# 1.1 * 0 + 1.1 * 1 - 1.0 = 0.1  -->  w2 + w0 >= 0\n",
    "# 1.1 * 1 + 1.1 * 0 - 1.0 = 0.1  -->  w1 + w0 >= 0\n",
    "# 1.1 * 1 + 1.1 * 1 - 1.0 = 1.2  -->  w1 + w2 + w0 >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePerceptron(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def heaviside(self, summe):\n",
    "        if summe >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        return None\n",
    "\n",
    "    def gewichtete_summe(self, x):\n",
    "        return self.w[1]*x[0] + self.w[2] * x[1] + self.w[0]\n",
    "        pass\n",
    "    \n",
    "    def perceptron_eval(self, X,y):\n",
    "        self.w = np.array([-1.0, 1.1, 1.1])\n",
    "        total_error = 0\n",
    "        for i in range (0, len(X)-1):\n",
    "            sum = self.gewichtete_summe(X[i])\n",
    "            result = self.heaviside(sum)\n",
    "            error = abs(result -y[i])\n",
    "            total_error += error\n",
    "        return total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithmus ausführuen und  Gesamtfehler anzeigen\n",
    "\n",
    "Führen Sie den SimplePerceptron-Algorithmus mit den beschriebenen Daten uns und geben Sie den Gesamtfehler aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# 2 dimensionaler Input: x1, x2\n",
    "# 4 Inputvektoren\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "\n",
    "# Die 4 gewünschten Ergebniswerte\n",
    "y = np.array([0, 1, 1, 1])\n",
    "\n",
    "# TODO: implement: USE SimplePerceptron\n",
    "sp = SimplePerceptron()\n",
    "print(sp.perceptron_eval(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
